{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41228961",
   "metadata": {},
   "source": [
    "## Task 2 (4 points)\n",
    "\n",
    "Your task is to train the embeddings for Simple Wikipedia titles, using gensim library. As the example below shows, training is really simple:\n",
    "\n",
    "```python\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "model.save(\"word2vec.model\")\n",
    "```\n",
    "*sentences* can be a list of list of tokens, you can also use *gensim.models.word2vec.LineSentence(source)* to create restartable iterator from file. At first, use [this file] containing such pairs of titles, that one article links to another.\n",
    "\n",
    "We say that two titles are *related* if they both contain a word (or a word bigram) which is not very popular (it occurs only in several titles). Make this definition more precise, and create the corpora which contains pairs of related titles. Make a mixture of the original corpora, and the new one, then train title vectors again.\n",
    "\n",
    "Compare these two approaches using similar code to the code from Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ddf626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter = Counter()\n",
    "with open(\"../data/L4/task2_simple.wiki.links.txt\", \"rt\") as f:\n",
    "    for line in f:\n",
    "        for link in line.split():\n",
    "            word_counter.update(link.split(\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, counts = zip(*word_counter.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 2\n",
    "max_count = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpopular_words = set(words[counts.index(max_count):counts.index(min_count)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "related_sentences = defaultdict(set)\n",
    "\n",
    "with open(\"../data/L4/task2_simple.wiki.links.txt\", \"rt\") as f:\n",
    "    for line in f:\n",
    "        for link in line.split():\n",
    "            for word in link.split(\"_\"):\n",
    "                related_sentences[word].add(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "839469"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(related_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88836"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpopular_words = [k for (k, v) in related_sentences.items() if min_count < len(v) < max_count]\n",
    "len(unpopular_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/L4/task2_similar_links.txt\", \"wt\") as f:\n",
    "    for word, links in related_sentences.items():\n",
    "        if min_count < len(links) < max_count:\n",
    "            for link1, link2 in itertools.combinations(links, 2):\n",
    "                f.write(f\"{link1} {link2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../data/L4/task2_similar_links.txt ../data/L4/task2_simple.wiki.links.txt  >../data/L4/task2_extended.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK2_FILEPATH = Path(\"../data/L4/task2.model\")\n",
    "if not TASK2_FILEPATH.exists():\n",
    "    model = gensim.models.Word2Vec(corpus_file=\"../data/L4/task2_simple.wiki.links.txt\", vector_size=30, window=2, min_count=1, workers=4)\n",
    "    model.save(str(TASK2_FILEPATH))\n",
    "else:\n",
    "    model = gensim.models.Word2Vec.load(str(TASK2_FILEPATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK2EXTENDED_FILEPATH = Path(\"../data/L4/task2_extended.model\")\n",
    "if not TASK2EXTENDED_FILEPATH.exists():\n",
    "    model_ex = gensim.models.Word2Vec(corpus_file=\"../data/L4/task2_extended.txt\", vector_size=30, window=2, min_count=1, workers=4)\n",
    "    model_ex.save(str(TASK2EXTENDED_FILEPATH))\n",
    "else:\n",
    "    model_ex = gensim.models.Word2Vec.load(str(TASK2EXTENDED_FILEPATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD: dog\n",
      "\tpoison                              [0.969]\tpoison                              [0.975]\n",
      "\tenvironment                         [0.966]\tanatomy                             [0.973]\n",
      "\tanatomy                             [0.965]\thorse                               [0.972]\n",
      "\tecology                             [0.956]\tenvironment                         [0.972]\n",
      "\tfemale                              [0.955]\tgenetics                            [0.967]\n",
      "\tcolor                               [0.955]\tgeology                             [0.966]\n",
      "\tgenetics                            [0.955]\trock_(geology)                      [0.966]\n",
      "\talcohol                             [0.955]\tmonkey                              [0.964]\n",
      "\tnature                              [0.954]\tsea                                 [0.963]\n",
      "\tpig                                 [0.952]\tmineral                             [0.962]\n",
      "\n",
      "WORD: dragon\n",
      "\tevergreen                           [0.987]\texistence                           [0.987]\n",
      "\tantelope                            [0.987]\tbrass                               [0.987]\n",
      "\tintroduced_species                  [0.986]\tc                                   [0.987]\n",
      "\tbean                                [0.985]\twool                                [0.985]\n",
      "\tcarcharhinidae                      [0.985]\tform                                [0.985]\n",
      "\tboidae                              [0.985]\tlaugh                               [0.985]\n",
      "\tcabbage                             [0.985]\tfinger                              [0.985]\n",
      "\trhinoceros                          [0.984]\tfertility                           [0.985]\n",
      "\tbag                                 [0.983]\tv                                   [0.984]\n",
      "\tpinniped                            [0.983]\tcape_york_peninsula                 [0.984]\n",
      "\n",
      "WORD: love\n",
      "\tbook                                [0.980]\tdrug                                [0.982]\n",
      "\tmachine                             [0.978]\tecology                             [0.982]\n",
      "\tdrug                                [0.976]\tenvironment                         [0.980]\n",
      "\talcohol                             [0.974]\texperiment                          [0.980]\n",
      "\thealth                              [0.973]\tbook                                [0.978]\n",
      "\trhythm                              [0.972]\tfiction                             [0.978]\n",
      "\ttheory                              [0.972]\trock_(geology)                      [0.977]\n",
      "\tman                                 [0.970]\talcohol                             [0.977]\n",
      "\tnature                              [0.969]\tintelligence                        [0.977]\n",
      "\texperiment                          [0.969]\tice                                 [0.977]\n",
      "\n",
      "WORD: bicycle\n",
      "\taccident                            [0.992]\tlibretto                            [0.990]\n",
      "\tscholar                             [0.992]\tairliner                            [0.989]\n",
      "\tprincess                            [0.992]\tdesigner                            [0.988]\n",
      "\tespionage                           [0.990]\tsecurity                            [0.987]\n",
      "\tillustration                        [0.990]\tcargo                               [0.987]\n",
      "\thanging                             [0.989]\tnazis                               [0.987]\n",
      "\tpretty._odd.                        [0.989]\tfighter_aircraft                    [0.987]\n",
      "\tsymphony                            [0.989]\taustrian                            [0.987]\n",
      "\tphysiologist                        [0.988]\tlist_of_decades                     [0.987]\n",
      "\t19_december                         [0.988]\tespionage                           [0.987]\n",
      "\n",
      "WORD: marathon\n",
      "\tfootballer                          [0.996]\ttyphoon                             [0.993]\n",
      "\t1919                                [0.995]\tfootballer                          [0.992]\n",
      "\t1954                                [0.995]\tzoologist                           [0.992]\n",
      "\t1946                                [0.995]\thumanitarian                        [0.992]\n",
      "\t1951                                [0.995]\t1951                                [0.992]\n",
      "\t1894                                [0.995]\t1954                                [0.992]\n",
      "\thumanitarian                        [0.994]\tcosmonaut                           [0.992]\n",
      "\t1887                                [0.994]\t1880                                [0.992]\n",
      "\t1961                                [0.994]\t1937                                [0.992]\n",
      "\t1952                                [0.994]\t1887                                [0.992]\n",
      "\n",
      "WORD: logic\n",
      "\toptics                              [0.989]\tphilosophy_of_science               [0.991]\n",
      "\tmechanics                           [0.988]\tacceleration                        [0.991]\n",
      "\tscientific_method                   [0.988]\tsystem                              [0.990]\n",
      "\tobservation                         [0.988]\tspecial_relativity                  [0.989]\n",
      "\tlist_of_science_books               [0.987]\tmechanics                           [0.989]\n",
      "\tphilosophy_of_science               [0.987]\tobservation                         [0.989]\n",
      "\tmind                                [0.986]\tmetaphysics                         [0.988]\n",
      "\tspeed                               [0.985]\ttool                                [0.988]\n",
      "\thand                                [0.984]\tnuclear_physics                     [0.988]\n",
      "\tsystem                              [0.984]\tcalculus                            [0.988]\n",
      "\n",
      "WORD: butterfly\n",
      "\tspider                              [0.991]\ttaxonomy                            [0.994]\n",
      "\tbeetle                              [0.990]\tspider                              [0.992]\n",
      "\tmollusc                             [0.990]\tvertebrate                          [0.992]\n",
      "\ttaxonomy                            [0.990]\tfungus                              [0.991]\n",
      "\tlarva                               [0.989]\tegg_(biology)                       [0.991]\n",
      "\tinvertebrate                        [0.988]\tmollusc                             [0.990]\n",
      "\tfungus                              [0.988]\tlepidoptera                         [0.990]\n",
      "\tlepidoptera                         [0.988]\tsymbiosis                           [0.990]\n",
      "\tvertebrate                          [0.988]\tinvertebrate                        [0.990]\n",
      "\talgae                               [0.987]\tbeetle                              [0.989]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_english_words = ['dog', 'dragon', 'love', 'bicycle', 'marathon', 'logic', 'butterfly']  # replace, or add your own examples\n",
    "\n",
    "for w0 in example_english_words:\n",
    "    print ('WORD:', w0)\n",
    "    for (w1, v1), (w2, v2) in zip(model.wv.most_similar(w0), model_ex.wv.most_similar(w0)):\n",
    "        print (f'\\t{w1:35} [{v1:.3f}]\\t{w2:35} [{v2:.3f}]')\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af3a108b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KeyedVectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jdworzans/projects/nn-and-nlp/L4/task2.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jdworzans/projects/nn-and-nlp/L4/task2.ipynb#ch0000015?line=0'>1</a>\u001b[0m task1_wv \u001b[39m=\u001b[39m KeyedVectors\u001b[39m.\u001b[39mload_word2vec_format(\u001b[39m'\u001b[39m\u001b[39mtask1_w2v_vectors.txt\u001b[39m\u001b[39m'\u001b[39m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jdworzans/projects/nn-and-nlp/L4/task2.ipynb#ch0000015?line=2'>3</a>\u001b[0m example_english_words \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mdog\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdragon\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlove\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbicycle\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmarathon\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlogic\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbutterfly\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# replace, or add your own examples\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jdworzans/projects/nn-and-nlp/L4/task2.ipynb#ch0000015?line=3'>4</a>\u001b[0m example_polish_words \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mpies\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msmok\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmiłość\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrower\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmaraton\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlogika\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmotyl\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KeyedVectors' is not defined"
     ]
    }
   ],
   "source": [
    "task1_wv = KeyedVectors.load_word2vec_format('task1_w2v_vectors.txt', binary=False)\n",
    "\n",
    "example_english_words = ['dog', 'dragon', 'love', 'bicycle', 'marathon', 'logic', 'butterfly']  # replace, or add your own examples\n",
    "example_polish_words = ['pies', 'smok', 'miłość', 'rower', 'maraton', 'logika', 'motyl']\n",
    "\n",
    "example_words = example_polish_words\n",
    "\n",
    "for w0 in example_words:\n",
    "    print ('WORD:', w)\n",
    "    for w, v in task1_wv.most_similar(w0):\n",
    "        print ('   ', w, v)\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ccde41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('west_berlin', 0.9919248223304749),\n",
       " ('sint_maarten', 0.9869701266288757),\n",
       " (\"people's_republic_of_bulgaria\", 0.9867256283760071),\n",
       " ('vojvodina', 0.9854137897491455),\n",
       " ('kingdom_of_greece', 0.9836078882217407),\n",
       " ('pitcairn_islands', 0.9828757643699646),\n",
       " ('eastern_europe', 0.9828706383705139),\n",
       " ('åland_islands', 0.9816504120826721),\n",
       " ('tokelau', 0.9813432693481445),\n",
       " ('holy_see', 0.980989933013916)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.wv.most_similar(\"east_berlin\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0294006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6ad8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cell for your presentation"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c9edea7d3c7f8afb1e3a5085762e5250f6cb461b15232d4b256ad3000efebc5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nn-and-nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
