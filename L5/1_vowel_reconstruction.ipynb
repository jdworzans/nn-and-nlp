{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faca5110",
   "metadata": {},
   "source": [
    "# Assigment 5\n",
    "\n",
    "**Submission deadlines**:\n",
    "\n",
    "* last lab before 27.06.2022 \n",
    "\n",
    "**Points:** Aim to get 12 out of 15+ possible points\n",
    "\n",
    "All needed data files are on Drive: <https://drive.google.com/drive/folders/1uufpGn46Mwv4oBwajIeOj4rvAK96iaS-?usp=sharing> (or will be soon :) )\n",
    "\n",
    "## Task 1 (5 points)\n",
    "\n",
    "Consider the vowel reconstruction task -- i.e. inserting missing vowels (aeuioy) to obtain proper English text. For instance for the input sentence:\n",
    "\n",
    "<pre>\n",
    "h m gd smbd hs stln ll m vwls\n",
    "</pre>\n",
    "\n",
    "the best result is\n",
    "\n",
    "<pre>\n",
    "oh my god somebody has stolen all my vowels\n",
    "</pre>\n",
    "\n",
    "In this task both dev and test data come from the two books about Winnie-the-Pooh. You have to train two RNN Language Models on *pooh-train.txt*. For the first model use the code below, for the second choose different hyperparameters (different dropout, smaller number of units or layers, or just do any modification you want). \n",
    "\n",
    "The code below is based on\n",
    "https://www.kdnuggets.com/2020/07/pytorch-lstm-text-generation-tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00d1cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict as dd\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2955fbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78d50e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 15\n",
    "\n",
    "class PoohDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequence_length, device):\n",
    "        txt = open('data/pooh_train.txt').read()\n",
    "        \n",
    "        self.words = txt.lower().split() # The text is already tokenized\n",
    "        \n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "        self.sequence_length = sequence_length\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.sequence_length], device=self.device),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1], device=self.device)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b22a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, dataset, device):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm_size = 512\n",
    "        self.embedding_dim = 100\n",
    "        self.num_layers = 2\n",
    "        self.device = device\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size).to(self.device),\n",
    "                torch.zeros(self.num_layers, sequence_length, self.lstm_size).to(self.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd1ed6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (embedding): Embedding(2548, 100)\n",
       "  (lstm): LSTM(100, 512, num_layers=2, dropout=0.2)\n",
       "  (fc): Linear(in_features=512, out_features=2548, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooh_dataset = PoohDataset(SEQUENCE_LENGTH, device)\n",
    "model = LSTMModel(pooh_dataset, device) \n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "074d5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, model):\n",
    "    model.train()\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        state_h, state_c = model.init_state(SEQUENCE_LENGTH)\n",
    "        \n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            loss = criterion(y_pred.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()            \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05c79cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "max_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c08be512",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"pooh_2x512_30ep.model\"\n",
    "try:\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "except FileNotFoundError:\n",
    "    train(pooh_dataset, model)\n",
    "    torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38520dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, model, text, next_words=15):\n",
    "    model.eval()\n",
    "\n",
    "    words = text.split()\n",
    "    state_h, state_c = model.init_state(len(words))\n",
    "\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
    "        x = x.to(device)\n",
    "        \n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().cpu().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        words.append(dataset.index_to_word[word_index])\n",
    "\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adb34c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the morning pooh and planted to piglet again . and then he had a friendly picked two and helpful . it silence in which kanga and roo are about .... small just here it is n't . it is n't sense , '' he added , `` because where you know what what\n",
      "in the morning piglet generally a present , and there was those , `` here there is too late much better where it . '' `` but let are me , '' said piglet . there was a long silence . `` now then , '' said piglet again . `` it 's a\n",
      "in the morning christopher robin i could think of something . '' `` why ? '' said rabbit . `` now , '' said piglet . `` what sort of a lesson , piglet ? '' `` well , '' said pooh , `` because i expect if i say 'now ! ' pooh can\n",
      "in the morning rabbit ca n't seem to this there ? '' `` just for a moment . '' `` perhaps owl , '' said piglet comfortingly . `` hallo and rabbit and rabbit ! '' `` so do i ? '' `` yes . '' everybody gave ; and two days later rabbit\n",
      "in the morning owl own jumped if the forest begin really can read something than anybody . and this was pooh and piglet had waited up off before they were all ready of the tracks next to rabbit 's house and rabbit fell in front of them , and kanga 's relations had coming\n",
      "in the morning tigger went on suddenly . `` there 's a good idea . '' `` oh , oh , i see . '' `` they 're bear very carefully . '' piglet `` oh ! '' cried pooh . `` oh ! '' said pooh . `` well , come here .\n",
      "in the morning eeyore ? '' `` the all thing , '' said owl excitedly , but the word ten ears behind piglet 's . you had fallen to christopher robin stuck . `` there 's a sort of greyish for a bee , '' and he brain to make quite sure . .\n"
     ]
    }
   ],
   "source": [
    "speakers = ['pooh', 'piglet', 'christopher robin', 'rabbit', 'owl', 'tigger', 'eeyore']\n",
    "for s in speakers:\n",
    "    prompt = 'in the morning ' + s \n",
    "    for i in range(1):\n",
    "        print(predict(pooh_dataset, model, prompt, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea1eb733",
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = set(\"aoiuye'\")\n",
    "def devowelize(s):\n",
    "    rv = ''.join(a for a in s if a not in vowels)\n",
    "    if rv:\n",
    "        return rv\n",
    "    return '_' # Symbol for words without consonants   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c1fc7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "863\n"
     ]
    }
   ],
   "source": [
    "pooh_words = set(open('data/pooh_words.txt').read().split())\n",
    "representation = dd(set)\n",
    "\n",
    "for w in pooh_words:\n",
    "    r = devowelize(w)\n",
    "    representation[r].add(w)\n",
    "    \n",
    "hard_words = set()\n",
    "for r, ws in representation.items():\n",
    "    if len(ws) > 1:\n",
    "        hard_words.update(ws)\n",
    "        \n",
    "print(len(hard_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aa49233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reconstruct(words: List[str], model, start: str, T: float):\n",
    "    model.eval()\n",
    "    corrected = []\n",
    "    state_h, state_c = model.init_state(1)\n",
    "    x = torch.tensor([[pooh_dataset.word_to_index[start]]], device=device)\n",
    "    plog = 0\n",
    "    for word in words:\n",
    "        possible_idxs = torch.tensor([pooh_dataset.word_to_index[k] for k in representation[word] if k in pooh_dataset.word_to_index], device=device)\n",
    "        y_pred, (new_state_h, new_state_c) = model(x, (state_h, state_c))\n",
    "        y_pred = y_pred[:, -1:].contiguous()\n",
    "        state_h, state_c = new_state_h[:, -1:, ...].contiguous(), new_state_c[:, -1:, ...].contiguous()\n",
    "        if possible_idxs.numel():\n",
    "            preds = F.softmax(y_pred.flatten()[possible_idxs] / T, -1)\n",
    "        else:\n",
    "            preds = F.softmax(y_pred.flatten() / T, -1)\n",
    "\n",
    "        selected = torch.multinomial(preds, 1)\n",
    "\n",
    "        if possible_idxs.numel():\n",
    "            x = possible_idxs[selected].reshape(1, -1)\n",
    "        else:\n",
    "            x = selected.reshape(1, -1)\n",
    "\n",
    "        corrected.append(pooh_dataset.index_to_word[x.item()])\n",
    "        plog += torch.log(preds[selected]).item()\n",
    "    return \" \".join([start] + corrected), plog\n",
    "\n",
    "def reconstruct(text: List[str], model, T: float, n_iter: int = 10):\n",
    "    if not text:\n",
    "        return []\n",
    "    model.eval()\n",
    "    max_plog = float(\"-inf\")\n",
    "    for start in representation[text[0]]:\n",
    "        for _ in range(n_iter):\n",
    "            correction, plog = _reconstruct(text[1:], model, start, T)\n",
    "            if plog > max_plog:\n",
    "                max_plog = plog\n",
    "                best_correction = correction\n",
    "    return best_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76ffa7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/pooh_test.txt\", \"rt\") as f:\n",
    "    test_tokens = f.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "571af0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = list(map(devowelize, test_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee361db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = reconstruct(test_input, model, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273881ae",
   "metadata": {},
   "source": [
    "You can assume that only words from pooh_words.txt can occur in the reconstructed text. For decoding you have two options (choose one, or implement both ang get **+1** bonus point)\n",
    "\n",
    "1. Sample reconstructed text several times (with quite a low temperature), choose the most likely result.\n",
    "2. Perform beam search.\n",
    "\n",
    "Of course in the sampling procedure you should consider only words matching the given consonants.\n",
    "\n",
    "Report accuracy of your methods (for both language models). The accuracy should be computed by the following function, it should be *greater than 0.25*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86a585a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(original_sequence, reconstructed_sequence):\n",
    "    sa = original_sequence\n",
    "    sb = reconstructed_sequence\n",
    "    score = len([1 for (a,b) in zip(sa, sb) if a == b])\n",
    "    return score / len(original_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be416f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7992090827911723"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(test_tokens, reconstructed.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16dcfbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTMModel(nn.Module):\n",
    "    def __init__(self, dataset, device):\n",
    "        super().__init__()\n",
    "        self.lstm_size = 512\n",
    "        self.embedding_dim = 100\n",
    "        self.num_layers = 3\n",
    "        self.device = device\n",
    "\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=n_vocab,\n",
    "            embedding_dim=self.embedding_dim,\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.3,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "        return logits, state\n",
    "\n",
    "    def init_state(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size).to(self.device),\n",
    "                torch.zeros(self.num_layers, sequence_length, self.lstm_size).to(self.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "902fa434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'batch': 113, 'loss': 5.569244861602783}\n",
      "{'epoch': 1, 'batch': 113, 'loss': 5.493239402770996}\n",
      "{'epoch': 2, 'batch': 113, 'loss': 5.4845290184021}\n",
      "{'epoch': 3, 'batch': 113, 'loss': 5.467758655548096}\n",
      "{'epoch': 4, 'batch': 113, 'loss': 5.461180210113525}\n",
      "{'epoch': 5, 'batch': 113, 'loss': 5.4551825523376465}\n",
      "{'epoch': 6, 'batch': 113, 'loss': 5.451696872711182}\n",
      "{'epoch': 7, 'batch': 113, 'loss': 5.446776866912842}\n",
      "{'epoch': 8, 'batch': 113, 'loss': 5.443249225616455}\n",
      "{'epoch': 9, 'batch': 113, 'loss': 5.441751480102539}\n",
      "{'epoch': 10, 'batch': 113, 'loss': 5.439263343811035}\n",
      "{'epoch': 11, 'batch': 113, 'loss': 5.437617778778076}\n",
      "{'epoch': 12, 'batch': 113, 'loss': 5.436402320861816}\n",
      "{'epoch': 13, 'batch': 113, 'loss': 5.433779239654541}\n",
      "{'epoch': 14, 'batch': 113, 'loss': 5.432648181915283}\n",
      "{'epoch': 15, 'batch': 113, 'loss': 5.439981460571289}\n",
      "{'epoch': 16, 'batch': 113, 'loss': 5.032291412353516}\n",
      "{'epoch': 17, 'batch': 113, 'loss': 4.681049823760986}\n",
      "{'epoch': 18, 'batch': 113, 'loss': 4.372686862945557}\n",
      "{'epoch': 19, 'batch': 113, 'loss': 4.117257595062256}\n",
      "{'epoch': 20, 'batch': 113, 'loss': 3.9418303966522217}\n",
      "{'epoch': 21, 'batch': 113, 'loss': 3.7714946269989014}\n",
      "{'epoch': 22, 'batch': 113, 'loss': 3.6195504665374756}\n",
      "{'epoch': 23, 'batch': 113, 'loss': 3.497875452041626}\n",
      "{'epoch': 24, 'batch': 113, 'loss': 3.3657681941986084}\n",
      "{'epoch': 25, 'batch': 113, 'loss': 3.2077431678771973}\n",
      "{'epoch': 26, 'batch': 113, 'loss': 3.088468551635742}\n",
      "{'epoch': 27, 'batch': 113, 'loss': 3.001101016998291}\n",
      "{'epoch': 28, 'batch': 113, 'loss': 2.878117799758911}\n",
      "{'epoch': 29, 'batch': 113, 'loss': 2.7648203372955322}\n"
     ]
    }
   ],
   "source": [
    "my_model = MyLSTMModel(pooh_dataset, device)\n",
    "my_model.to(device)\n",
    "\n",
    "my_filename = \"pooh_my_3x512_30ep.model\"\n",
    "try:\n",
    "    my_model.load_state_dict(torch.load(my_filename))\n",
    "except FileNotFoundError:\n",
    "    train(pooh_dataset, my_model)\n",
    "    torch.save(my_model.state_dict(), my_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2a1bcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8192371475953566"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_reconstructed = reconstruct(test_input, my_model, 1)\n",
    "accuracy(test_tokens, my_reconstructed.split())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
