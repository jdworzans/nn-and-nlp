{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41e84582",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "In this task you have to create a network which looks at characters of the word and tries to guess whether the word is a noun, a verb, an adjective, and so on. To be more precise: the input is a word (without context), the output is a POS-tag (Part-of-Speech). Since some words are unambiguous, and we have no context, our network is supposed to return the set of possible tags.\n",
    "\n",
    "The data is taken from Universal Dependencies English corpus, and of course it contains errors, especially because not all possible tags occured in the data.\n",
    "\n",
    "Train a network (4p) or two networks (+2p) solving this task. Both networks should look at character n-grams occuring in the word. There are two options:\n",
    "\n",
    "* **Fixed size:** for instance take 2,3, and 4-character suffixes of the word, use them as  features (whith 1-hot encoding). You can also combine prefix and suffix features. Simple, useful trick: when looking at suffixes, add some '_' characters at the beginning of the word to guarantee that shorter words have suffixes of a desired length.\n",
    "\n",
    "* **Variable size:** take for instance 4-grams (or 4 grams and 3-grams), use Deep Averaging Network. Simple trick: add extra character at the beginning and at the end of the word, to add the information, that ngram occurs at special position ('ed' at the end has slightly different meaning that 'ed' in the middle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "615068bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torchtext import vocab\n",
    "from scipy import sparse\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4feefe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"data\")\n",
    "TRAIN_FILEPATH = DATA_PATH / \"english_tags_dev.txt\"\n",
    "TEST_FILEPATH = DATA_PATH / \"english_tags_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cbfe9bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Confidence</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>DT_IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pound</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is</td>\n",
       "      <td>NNS_VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expected</td>\n",
       "      <td>VBD_VBN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word   labels\n",
       "0  Confidence       NN\n",
       "1         the    DT_IN\n",
       "2       pound       NN\n",
       "3          is  NNS_VBZ\n",
       "4    expected  VBD_VBN"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(TRAIN_FILEPATH, sep=\" \", names=[\"word\", \"labels\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "29640542",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = df[\"labels\"].str.split(\"_\").explode().value_counts()\n",
    "ID_TO_LABEL = dict(enumerate(label_counts.index))\n",
    "LABEL_TO_ID = {k: v for v, k in ID_TO_LABEL.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "25ef8cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ry$', '$di', 'ary$', '$dic', 'nary$', '$dict']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process(word):\n",
    "    result = []\n",
    "    for i in [2, 3, 4]:\n",
    "        result.append((\"____\" + word)[-i:] + \"$\")\n",
    "        result.append(\"$\" + (word + \"____\")[:i])\n",
    "    return result\n",
    "process(\"dictionary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0bfc3f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vocab = vocab.build_vocab_from_iterator(map(process, df[\"word\"]))\n",
    "label_vocab = vocab.build_vocab_from_iterator(df[\"labels\"].str.split(\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "082746a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sparse.lil_array((len(df), len(input_vocab))), sparse.lil_array((len(df), len(label_vocab)))\n",
    "for word_idx, (subwords, labels) in enumerate(zip(map(process, df[\"word\"]), df[\"labels\"].str.split(\"_\"))):\n",
    "    X[word_idx, [input_vocab[subword] for subword in subwords]] = 1\n",
    "    y[word_idx, [label_vocab[label] for label in labels]] = 1\n",
    "X, y = X.tocsr(), y.tocsr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nn-and-nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c9edea7d3c7f8afb1e3a5085762e5250f6cb461b15232d4b256ad3000efebc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
