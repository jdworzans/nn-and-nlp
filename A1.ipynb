{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# NN 2022",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 0
    },
    "is_collapsed": false,
    "tags": [],
    "cell_id": "404fe76d-6335-4b7b-a4a5-e073ca73825e",
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Assignment 1\n\n**Submission deadlines:** \n- get at least **2** points by Tuesday, 15.03.2022\n- remaining points: last lab session before or on Tuesday, 22.03.2022\n\n**Points:** Aim to get 8 out of 12 possible points\n\n## Submission instructions\nThe class is held on-site in lab rooms. Please prepare you notebook on your computer or anywhere in the cloud (try using DeepNote or Google Colab).\nMake sure you know all the questions and asnwers, and that the notebook contains results; bfore presentation do `Runtime -> Restart and run all`\n![Picture title](image-20220302-183151.png)\n\nWe provide starter code, however you are not required to use it as long as you properly solve the tasks.\n",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 6
    },
    "id": "CGXgWugfJ0Vl",
    "cell_id": "00001-9f25cf52-28e9-4f83-8af1-f25c1c5f1910",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 418.125
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Task description\n\n## TLDR\nImplement and train a neural network using pure numpy.",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 12
    },
    "id": "5S8iRaCPyO2a",
    "cell_id": "00002-467d4f7c-b1fd-4a38-9743-bce105dc1f1b",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 176.390625
   }
  },
  {
   "cell_type": "markdown",
   "source": "\n## Problem 1 [2p]\nImplement a two-layer network, manually set weights and biases to solve the XOR task.\n\nA two-layer neural network implementes a function $f: \\mathbb{R}^D \\rightarrow \\mathbb{R}^O$ where $D$ is the input dimensionality and $O$ is the output dinemsionality. The output goes through an intermediate representation (the hidden layer) with dimensionality $H$. \n\nThe computations are as follows:\n$$\n\\begin{aligned}\nA_1 &= x W_1^T + b_1  & \\qquad\\text{Total input to neurons in the hidden layer (network's first layer)} \\\\\nO_1 &= \\sigma_1(A_1)  & \\qquad\\text{Output of the hidden layer} \\\\\nA_2 &= O_1 W_2^T + b_2 & \\qquad\\text{Total input to neurons in the output layer (network's second layer)}\\\\\nO_2 &= \\sigma_2(A_2)  & \\qquad\\text{Output of the network}\n\\end{aligned}\n$$\n\nWhere $W$ are weight matrices, $b$ are bias vectors, $\\sigma$ are non-linear activation functions (e.g. the logistic sigmoid applied element-wise, or softmax).\n\nFor the 2D xor problem the network will:\n- have 2 inputs, 2 hidden neurons, one output\n- use the logistic sigmoid everywhere (that way we, when hand-designig the weights, we can assume that neurons' outputs are binary).\n\nTherrefore the shapes of the data flowing through the network will be:\n- input: $x\\in\\mathbb{}R^{2}$\n- hidden layer parameters: $W_1\\in\\mathbb{}R^{2\\times 2}$ and $b_1\\in\\mathbb{}R^{2}$\n- representations in the hidden layer: $A_1\\in\\mathbb{}R^{2}$ and $O_1\\in\\mathbb{}R^{2}$\n- output layer parameters: $W_2\\in\\mathbb{}R^{1\\times 2}$ and $b_2\\in\\mathbb{}R^{1}$\n- representations in the output layer: $A_2\\in\\mathbb{}R^{1}$ and $O_2\\in\\mathbb{}R^{1}$\n\nThe network can be seen as a logistic regression model, prefixed by a nonlinear transformation of the data.\n\nThe first tasks consists of:\n- implementing the network\n- selecting parametwrs ($W_1, b_1, W_2, b_2$) such that $f(x)\\approx XOR(x_1, x_2)$ where the approximation is die to the sigmoids - the output may be close to 0 or 1, but doesn't need to saturate at 0 or 1.\n\nNB: the convention on weight matrix shapes follows linear [layers in PyTorch](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html).\n",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 18
    },
    "id": "JHcz7I2V-bVM",
    "cell_id": "00003-b49a0011-3c5e-4f7e-bf92-4e45b1c74619",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 800.796875
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 2 [2p]\n1. Add a backward pass.\n2. Use a sensible random initialization for weights and biases.\n3. Numerically check the correctness of your gradient computation.\n\nThere is nice article about taking derivative over vectors and vector chain rule: https://explained.ai/matrix-calculus/ if someone don't have experience with suchr calculus.\n",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 24
    },
    "id": "0QSpZxuH-bLe",
    "cell_id": "00004-d8f9c747-63c5-4c54-b404-523ca3ec8a4c",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 195.5625
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 3 [2p]\n1. Implement gradient descent\n2. Train your network to solve 3D XOR\n3. Try several hidden layer sizes, for each size record the fracton of successful trainings. Then answer:\n    - What is the minimal hidden size required to solve 3D XOR (even with low reliability, when the training has to be repeated multiple times)\n    - What is the minimal hidden size required to reliably solve 3D XOR\n    - Which networks are easier to train - small or large ones? Why?\n",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 30
    },
    "id": "s1Tn8j0m-bAy",
    "cell_id": "00005-4cdbe891-e246-43bf-9d7d-89849148ee8c",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 249.34375
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 4 [1p]\nReplace the first nonlinearity with the [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) activation function. Find a network architecture which reliably learns the 3D XOR problem.\n",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 36
    },
    "id": "RP9Pvpmf-a2A",
    "cell_id": "00006-9e2df4c3-0062-4162-916e-1c17cd36d950",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 108.390625
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 5 [1p]\nAdd a second hidden layer to your network, implement the forward and backward pass, then demonstrate training.\n",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 42
    },
    "id": "cGgtpe-w-asB",
    "cell_id": "00007-5f778f94-25ad-4f64-a823-464daf0c5255",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 108.390625
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 6 [2p]\nImplement a way to have a _variable number_ of hidden layers. Check how deep sigmoid or ReLU networks you  can train. For simplicity you can assume that all hidden layers have the same number of neurons, and use the same activation function.\n",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 48
    },
    "id": "Pe-pcFeO-aiE",
    "cell_id": "00008-a2c7b4c2-4128-45b0-a1ae-2125d1f97664",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 130.78125
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 7 [2p]\nFor each weight matrix $w\\in\\mathbb{R}^{n\\times m}$, add a randomly initialized `backward weight` $w_b\\in\\mathbb{R}^{m\\times n}$, which will not change during training. Change the backward pass to use $w_b$ instead of $w^T$, getting an approxmatoin of the true gradient. Can you get your network to train?\n\nNB: this approach, dubbed [feedback alignment](https://www.nature.com/articles/ncomms13276), was proposed to make error backpropagation more biologically plausible, by providing a solution to the \"weight transport problem\". Regular backpropagation requires that neurons not only know their incoming weights (thet they control), but also their outgoing weights (that are controlled by neurons in the upper layers). This is nearly impossible in a real brain.",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 54
    },
    "id": "kIpn17Cm-aW7",
    "cell_id": "00009-a7eb99aa-76d2-47a4-912e-894e0cce5c9c",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 211.953125
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Solutions and starter code",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 60
    },
    "id": "rXJaoHSH0DZO",
    "cell_id": "00010-55453e63-a8e4-4570-86af-be6b9f68e534",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 82
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 66
    },
    "id": "YiTEWD2oqW0Y",
    "cell_id": "00011-945d3e01-d9e1-4fbe-805a-07c9db9d8a1f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bf903efd",
    "execution_start": 1647800749360,
    "execution_millis": 10268,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 135
   },
   "source": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "XOR dataset creation",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 72
    },
    "id": "eqtfJKR40J3x",
    "cell_id": "00012-2b197fd1-ac63-45f7-862b-8e6b580ae0b9",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 52.390625
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 78
    },
    "id": "lYEbCfbSpv5M",
    "outputId": "48a99aad-e15b-4c7b-f881-bbfbe1941a15",
    "cell_id": "00013-6cf61f31-5b7f-4abb-8ad7-b80b9840335d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2188275c",
    "execution_start": 1647800759695,
    "execution_millis": 721,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 629.1875,
    "deepnote_output_heights": [
     21.1875,
     264
    ]
   },
   "source": "# Let's define a XOR dataset\n\n# X will be matrix of N 2-dimensional inputs\nX = np.array([[0, 0], [0, 1], [1, 0], [1, 1],], dtype=np.float32)\n# Y is a matrix of N numners - answers\nY = np.array([[0], [1], [1], [0],], dtype=np.float32)\n\nplt.scatter(\n    X[:, 0], X[:, 1], c=Y[:, 0],\n)\nplt.xlabel(\"X[0]\")\nplt.ylabel(\"X[1]\")\nplt.axis(\"square\")",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 2,
     "data": {
      "text/plain": "(-0.05, 1.05, -0.05, 1.05)"
     },
     "metadata": {}
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light",
      "image/png": {
       "width": 268,
       "height": 262
      }
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 1",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 84
    },
    "id": "Rb3azMn929_I",
    "cell_id": "00014-151c37cc-2599-4aaf-916d-78e26bd95f73",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "markdown",
   "source": "The code below contains a mock-up of a two-layer neural network. Fill in the code and manually set weights to solve the XOR problem.\n\nPlease note: the shapes are set to be compatible with PyTorch's conventions:\n* a batch containing $N$ $D$-dimensional examples has shape $N\\times D$ (each example is a row!)\n* a weight matrix in a linear layer with $I$ inputs and $O$ outputs has shape $O \\times I$\n* a bias vector is a 1D vector. Please note that [broadcasting rules](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) allow us to think about it as a $1 \\times D$ matrix.",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 90
    },
    "id": "RZCM_hdELE04",
    "cell_id": "00015-19b8330e-56da-4944-a6b9-fb6f370e4738",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 189.953125
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00016-4935fedf-9c63-4c82-a286-8713af059323",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a4acaf66",
    "execution_start": 1647800760451,
    "execution_millis": 9,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 99
   },
   "source": "def sigmoid(x):\n    return 1 / (1 + np.exp(-x))",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00017-f75f74c4-b7f6-4fc2-8716-9ddd1fbc7743",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6473edd3",
    "execution_start": 1647800760494,
    "execution_millis": 384,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 383,
    "deepnote_output_heights": [
     250
    ]
   },
   "source": "t = np.linspace(-5, 5)\nplt.plot(t, sigmoid(t))\nplt.show()",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light",
      "image/png": {
       "width": 372,
       "height": 248
      }
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 96
    },
    "id": "lrrRuk6zLiF0",
    "cell_id": "00018-b30ed8cd-e3ca-4a1d-87fb-9f1d52660e3b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d7313fa3",
    "execution_start": 1647800761111,
    "execution_millis": 44,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1071
   },
   "source": "class SmallNet:\n    def __init__(self, in_features, num_hidden, dtype=np.float32):\n        self.W1 = np.zeros((num_hidden, in_features), dtype=dtype)\n        self.b1 = np.zeros((num_hidden,), dtype=dtype)\n        self.W2 = np.zeros((1, num_hidden), dtype=dtype)\n        self.b2 = np.zeros((1,), dtype=dtype)\n        self.init_params()\n\n    def init_params(self):\n        self.W1 = np.random.normal(0, 0.5, self.W1.shape)\n        self.b1 = np.random.normal(0, 0.5, self.b1.shape)\n        self.W2 = np.random.normal(0, 0.5, self.W2.shape)\n        self.b2 = np.random.normal(0, 0.5, self.b2.shape)\n\n    def forward(self, X, Y=None, do_backward=False):\n        # TODO Problem 1: Fill in details of forward propagation\n\n        # Input to neurons in 1st layer\n        A1 = np.dot(X, self.W1.T) + self.b1\n        # Outputs after the sigmoid non-linearity\n        O1 = sigmoid(A1)\n        # print(O1)\n        # Inputs to neuron in the second layer\n        A2 = np.dot(O1, self.W2.T) + self.b2\n        # Outputs after the sigmoid non-linearity\n        O2 = sigmoid(A2)\n\n        # When Y is none, simply return the predictions. Else compute the loss\n        if Y is not None:\n            loss = -np.sum((1 - Y) * np.log(1 - O2) + Y * np.log(O2)) # TODO cross-entropy loss\n            # normalize loss by batch size\n            loss = loss.sum() / X.shape[0]\n        else:\n            loss = np.nan\n\n        if do_backward:\n            # TODO in Problem 2:\n            # fill in the gradient computation/\n            # Please note, that there is a correspondance between\n            # the forward and backward pass: with backward computations happening\n            # in reverse order.\n            # We save the gradients with respect to the parameters as fields of self.\n            # It is not very elegant, but simplifies training code later on.\n\n            # A2_grad is the gradient of loss with respect to A2\n            # Hint: there is a concise formula for the gradient\n            # of logistic sigmoid and cross-entropy loss\n            A2_grad = (O2 - Y) / X.shape[0]\n            self.b2_grad = A2_grad.sum(0)\n            self.W2_grad = np.dot(A2_grad.T, O1)\n            O1_grad = np.dot(A2_grad, self.W2)\n            A1_grad = O1_grad * O1 * (1 - O1)\n            self.b1_grad = A1_grad.sum(0)\n            self.W1_grad = np.dot(A1_grad.T, X)\n\n        return O2, loss",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 102
    },
    "id": "jJswvBk0oiIY",
    "outputId": "e6559317-7afa-4509-fbac-4880e73b91cc",
    "cell_id": "00019-255503cc-e591-494a-9dc6-ef0f38b1cfa4",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cf947032",
    "execution_start": 1647800761171,
    "execution_millis": 33,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 424.75
   },
   "source": "# TODO Problem 1:\n# Set by hand the weight values to solve the XOR problem\n\nnet = SmallNet(2, 2, dtype=np.float64)\nnet.W1 = 10 * np.array([[1, -1], [-1, 1]])\nnet.b1 = -5 * np.array([1, 1])\nnet.W2 = 10 * np.array([[1, 1]])\nnet.b2 = 5 * np.array([-1])\n\n# Hint: since we use the logistic sigmoid activation, the weights may need to\n# be fairly large\n\npredictions, loss = net.forward(X, Y)#, do_backward=True)\nfor x, p in zip(X, predictions):\n    print(f\"XORnet({x}) = {p[0]}\")",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": "XORnet([0. 0.]) = 0.007644135828260396\nXORnet([0. 1.]) = 0.9928472118111036\nXORnet([1. 0.]) = 0.9928472118111036\nXORnet([1. 1.]) = 0.007644135828260396\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 2",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 108
    },
    "id": "wmxCi5Vl6_xB",
    "cell_id": "00020-2556c89c-1056-4a7a-87dc-66e668ae2ba8",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 114
    },
    "id": "eSM5hgJ1mrhY",
    "cell_id": "00021-d8f31d84-7ea5-4ed1-ae6d-500166997540",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e5739133",
    "execution_start": 1647800761268,
    "execution_millis": 1,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 477
   },
   "source": "def check_grad(net, param_name, X, Y, eps=1e-5):\n    \"\"\"A gradient checking routine\"\"\"\n\n    param = getattr(net, param_name)\n    param_flat_accessor = param.reshape(-1)\n\n    grad = np.empty_like(param)\n    grad_flat_accessor = grad.reshape(-1)\n\n    net.forward(X, Y, do_backward=True)\n    orig_grad = getattr(net, param_name + \"_grad\")\n    assert param.shape == orig_grad.shape, f\"{param_name} size doesn't match the gradient shape\"\n\n    for i in range(param_flat_accessor.shape[0]):\n        orig_val = param_flat_accessor[i]\n        param_flat_accessor[i] = orig_val + eps\n        _, loss_positive = net.forward(X, Y)\n        param_flat_accessor[i] = orig_val - eps\n        _, loss_negative = net.forward(X, Y)\n        param_flat_accessor[i] = orig_val\n        grad_flat_accessor[i] = (loss_positive - loss_negative) / (2 * eps)\n    assert np.allclose(grad, orig_grad)\n    return grad, orig_grad",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 120
    },
    "id": "TTZu0jFEvgXF",
    "cell_id": "00022-469419d1-d9c8-4718-aced-6234c3100b50",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d877662e",
    "execution_start": 1647800761316,
    "execution_millis": 2,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 153
   },
   "source": "# Hint: use float64 for checking the correctness of the gradient\nnet = SmallNet(2, 2, dtype=np.float64)\n\nfor param_name in [\"W1\", \"b1\", \"W2\", \"b2\"]:\n    check_grad(net, param_name, X, Y)",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 3",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 126
    },
    "id": "8mUOs3cVvjM2",
    "cell_id": "00023-ff41941b-cac9-41e2-839c-731e7ef7c3cc",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 132
    },
    "id": "nn2AAoZo0vjU",
    "outputId": "7b6b5a9a-dea5-4357-e8c1-36a34c7c272a",
    "cell_id": "00024-8644aedf-c80d-4480-a770-4779a93c31d3",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d6804775",
    "execution_start": 1647800761380,
    "execution_millis": 41877,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 747.75
   },
   "source": "net = SmallNet(2, 10, dtype=np.float64)\n\nalpha = 0.1  # set a learning rate\n\nfor i in range(100000):\n    _, loss = net.forward(X, Y, do_backward=True)\n    if (i % 5000) == 0:\n        print(f\"after {i} steps \\tloss={loss}\")\n    for param_name in [\"W1\", \"b1\", \"W2\", \"b2\"]:\n        param = getattr(net, param_name)\n        # Hint: use the construct `param[:]` to change the contents of the array!\n        # Doing instead `param = new_val` simply changes to what the variable\n        # param points to, without affecting the network!\n        # alternatively, you could do setattr(net, param_name, new_value)\n        param[:] = param[:] - alpha * getattr(net, param_name + \"_grad\")",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": "after 0 steps \tloss=0.6963123322012963\nafter 5000 steps \tloss=0.028932594455747782\nafter 10000 steps \tloss=0.008902325763582207\nafter 15000 steps \tloss=0.0051124090101034945\nafter 20000 steps \tloss=0.0035559731597063107\nafter 25000 steps \tloss=0.0027153199142089567\nafter 30000 steps \tloss=0.002191112837730128\nafter 35000 steps \tloss=0.001833799219679513\nafter 40000 steps \tloss=0.0015750049295246795\nafter 45000 steps \tloss=0.0013791211573919156\nafter 50000 steps \tloss=0.001225809302220623\nafter 55000 steps \tloss=0.0011026216686817534\nafter 60000 steps \tloss=0.0010015193949830796\nafter 65000 steps \tloss=0.0009170825827009296\nafter 70000 steps \tloss=0.0008455258952270661\nafter 75000 steps \tloss=0.0007841266048597307\nafter 80000 steps \tloss=0.0007308768102568475\nafter 85000 steps \tloss=0.00068426369334585\nafter 90000 steps \tloss=0.0006431260470732042\nafter 95000 steps \tloss=0.0006065579044718741\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 138
    },
    "id": "TwpEjpkU1JvK",
    "outputId": "dc044de9-81c1-4944-d9a2-5dcc72bf9a57",
    "cell_id": "00025-08198673-f06d-4e12-ac90-d566796b6cdd",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7b623984",
    "execution_start": 1647800803290,
    "execution_millis": 365,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 208.75
   },
   "source": "predictions, loss = net.forward(X, Y, do_backward=True)\nfor x, p in zip(X, predictions):\n    print(f\"XORnet({x}) = {p[0]}\")",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": "XORnet([0. 0.]) = 0.00025122695268924255\nXORnet([0. 1.]) = 0.9996070441045728\nXORnet([1. 0.]) = 0.99923758122284\nXORnet([1. 1.]) = 0.0008879730343009348\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00026-9e7f071c-a904-4720-a5b5-06545523b7af",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "215f7c04",
    "execution_start": 1647800803338,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "from itertools import repeat, product",
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00027-8eaad004-1890-4250-8a6a-6cf9ec32aa9f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6eda2a71",
    "execution_start": 1647800803377,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 442,
    "deepnote_output_heights": [
     309
    ]
   },
   "source": "X3 = np.array(list(product(*repeat([0, 1], 3))))\nY3 = np.logical_xor.reduce(X3, axis=1, keepdims=True).astype(float)\nX3, Y3",
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 12,
     "data": {
      "text/plain": "(array([[0, 0, 0],\n        [0, 0, 1],\n        [0, 1, 0],\n        [0, 1, 1],\n        [1, 0, 0],\n        [1, 0, 1],\n        [1, 1, 0],\n        [1, 1, 1]]),\n array([[0.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [1.]]))"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00028-4d10c354-d023-4629-9f09-bbd069fff73b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fa94b975",
    "execution_start": 1647800803456,
    "execution_millis": 202,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 118.1875,
    "deepnote_output_heights": [
     21.1875
    ]
   },
   "source": "np.log10(101) == np.log10(101).round()",
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 13,
     "data": {
      "text/plain": "False"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00029-2169ce91-3510-43cb-831d-cd0a51a6df6c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "11b2dff6",
    "execution_start": 1647800803500,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 118.1875,
    "deepnote_output_heights": [
     21.1875
    ]
   },
   "source": "np.log10(101).round()",
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 14,
     "data": {
      "text/plain": "2.0"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 144
    },
    "id": "U0ZMyHqz8xrC",
    "cell_id": "00030-20e43cbb-78df-4709-85df-79c2edd30d0c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "83206cc9",
    "execution_start": 1647800803501,
    "execution_millis": 923226,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 369
   },
   "source": "alpha = 0.1  # set a learning rate\nn_repeats = 10\nresults = []\n\nfor hidden_dim in [2, 3, 5, 10, 20]:\n    for _ in range(n_repeats):\n        net = SmallNet(3, hidden_dim, dtype=np.float64)\n        for i in range(1, 100001):\n            _, loss = net.forward(X3, Y3, do_backward=True)\n            for param_name in [\"W1\", \"b1\", \"W2\", \"b2\"]:\n                param = getattr(net, param_name)\n                param[:] = param[:] - alpha * getattr(net, param_name + \"_grad\")\n            \n            if (np.log10(i) == np.log10(i).round()):\n                results.append(\n                    {\"epochs\": i, \"accuracy\": (net.forward(X3)[0].round() == Y3).mean(), \"loss\": loss, \"hidden_dim\": hidden_dim}\n                )",
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00031-d85647bf-b419-4bc5-bde5-ef94ca1b32ec",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e0c6f18c",
    "execution_start": 1647801726772,
    "execution_millis": 983,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 383,
    "deepnote_output_heights": [
     268
    ]
   },
   "source": "sns.lineplot(x=\"epochs\", y=\"accuracy\", hue=\"hidden_dim\", data=pd.DataFrame(results).groupby([\"hidden_dim\", \"epochs\"]).mean()[\"accuracy\"].reset_index())\nplt.xscale(\"log\")",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light",
      "image/png": {
       "width": 386,
       "height": 266
      }
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00032-d443e0bd-5f7a-4172-83a2-e55e4b63be84",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bd9f3230",
    "execution_start": 1647801727766,
    "execution_millis": 1246,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 383,
    "deepnote_output_heights": [
     268
    ]
   },
   "source": "sns.lineplot(x=\"epochs\", y=\"loss\", hue=\"hidden_dim\", data=pd.DataFrame(results).groupby([\"hidden_dim\", \"epochs\"]).mean()[\"loss\"].reset_index())\nplt.xscale(\"log\")",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light",
      "image/png": {
       "width": 386,
       "height": 266
      }
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 4\n",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 150
    },
    "id": "UuaLEoV-9DLG",
    "cell_id": "00033-1a68a301-118f-4835-9e30-735f5408cafd",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 156
    },
    "id": "w3lk9_TM-MvK",
    "cell_id": "00034-2056e2ee-0332-41f1-9a18-ffcd6068bf3d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f36c7bf6",
    "execution_start": 1647801728619,
    "execution_millis": 0,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 747
   },
   "source": "class ReLUNet(SmallNet):\n    def forward(self, X, Y=None, do_backward=False):\n        # Input to neurons in 1st layer\n        A1 = np.dot(X, self.W1.T) + self.b1\n        # Outputs after the ReLU non-linearity\n        O1 = np.fmax(0, A1)\n        # Inputs to neuron in the second layer\n        A2 = np.dot(O1, self.W2.T) + self.b2\n        # Outputs after the sigmoid non-linearity\n        O2 = sigmoid(A2)\n\n        # When Y is none, simply return the predictions. Else compute the loss\n        if Y is not None:\n            loss = -np.sum((1 - Y) * np.log(1 - O2) + Y * np.log(O2)) # TODO cross-entropy loss\n            # normalize loss by batch size\n            loss = loss.sum() / X.shape[0]\n        else:\n            loss = np.nan\n\n        if do_backward:\n            # Please note, that there is a correspondance between\n            # the forward and backward pass: with backward computations happening\n            # in reverse order.\n            # We save the gradients with respect to the parameters as fields of self.\n            # It is not very elegant, but simplifies training code later on.\n\n            # A2_grad is the gradient of loss with respect to A2\n            # Hint: there is a concise formula for the gradient\n            # of logistic sigmoid and cross-entropy loss\n            A2_grad = (O2 - Y) / X.shape[0]\n            self.b2_grad = A2_grad.sum(0)\n            self.W2_grad = np.dot(A2_grad.T, O1)\n            O1_grad = np.dot(A2_grad, self.W2)\n            A1_grad = O1_grad * np.where(O1 == 0, 0, 1)\n            self.b1_grad = A1_grad.sum(0)\n            self.W1_grad = np.dot(A1_grad.T, X)\n\n        return O2, loss",
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00035-ece2742c-68ea-4d70-bbae-7faf9f3ed2ae",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f88503b6",
    "execution_start": 1647801728647,
    "execution_millis": 15715,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 747.75
   },
   "source": "net = ReLUNet(3, 10)\n\nalpha = 0.01  # set a learning rate\n\nfor i in range(100000):\n    _, loss = net.forward(X3, Y3, do_backward=True)\n    if (i % 5000) == 0:\n        print(f\"after {i} steps \\tloss={loss}\")\n    for param_name in [\"W1\", \"b1\", \"W2\", \"b2\"]:\n        param = getattr(net, param_name)\n        # Hint: use the construct `param[:]` to change the contents of the array!\n        # Doing instead `param = new_val` simply changes to what the variable\n        # param points to, without affecting the network!\n        # alternatively, you could do setattr(net, param_name, new_value)\n        param[:] = param[:] - alpha * getattr(net, param_name + \"_grad\")",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": "after 0 steps \tloss=0.8162663649350432\nafter 5000 steps \tloss=0.5883368170393728\nafter 10000 steps \tloss=0.44390531427033697\nafter 15000 steps \tloss=0.25374184634411523\nafter 20000 steps \tloss=0.10728986693007304\nafter 25000 steps \tloss=0.05477187139599242\nafter 30000 steps \tloss=0.03348377619052567\nafter 35000 steps \tloss=0.023315807403961296\nafter 40000 steps \tloss=0.017461102754035868\nafter 45000 steps \tloss=0.013748338505138393\nafter 50000 steps \tloss=0.011220258668995375\nafter 55000 steps \tloss=0.009409957470302365\nafter 60000 steps \tloss=0.008058526305590346\nafter 65000 steps \tloss=0.007017401395685627\nafter 70000 steps \tloss=0.006193877451799083\nafter 75000 steps \tloss=0.005528555612985445\nafter 80000 steps \tloss=0.004981561103108396\nafter 85000 steps \tloss=0.004524610237495178\nafter 90000 steps \tloss=0.0041383514090271535\nafter 95000 steps \tloss=0.003807625708777346\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00036-a13c4a25-382b-4809-bf92-4ba4c233d8e4",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3b4e28ee",
    "execution_start": 1647801744371,
    "execution_millis": 171,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 112.1875
   },
   "source": "print(f\"accuracy: {(net.forward(X3)[0].round() == Y3).mean()}\")",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": "accuracy: 1.0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 5",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 162
    },
    "id": "_Hr_iAKX-ND1",
    "cell_id": "00037-45887b22-8d5c-40f7-bc1e-e39369649578",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00038-85679282-618d-45ad-8843-ffd5c29523e6",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a10a3f58",
    "execution_start": 1647801744408,
    "execution_millis": 8,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1017
   },
   "source": "class DeepNet:\n    def __init__(self, in_features, num_hidden, dtype=np.float32):\n        self.W1 = np.zeros((num_hidden[0], in_features), dtype=dtype)\n        self.b1 = np.zeros((num_hidden[0],), dtype=dtype)\n        self.W2 = np.zeros((num_hidden[1], num_hidden[0]), dtype=dtype)\n        self.b2 = np.zeros((num_hidden[1],), dtype=dtype)\n        self.W3 = np.zeros((1, num_hidden[1]), dtype=dtype)\n        self.b3 = np.zeros((1,), dtype=dtype)\n        self.init_params()\n\n    def init_params(self):\n        self.W1 = np.random.normal(0, 0.5, self.W1.shape)\n        self.b1 = np.random.normal(0, 0.5, self.b1.shape)\n        self.W2 = np.random.normal(0, 0.5, self.W2.shape)\n        self.b2 = np.random.normal(0, 0.5, self.b2.shape)\n        self.W3 = np.random.normal(0, 0.5, self.W3.shape)\n        self.b3 = np.random.normal(0, 0.5, self.b3.shape)\n\n    def forward(self, X, Y=None, do_backward=False):\n        # Input to neurons in 1st layer\n        A1 = np.dot(X, self.W1.T) + self.b1\n        O1 = sigmoid(A1)\n        \n        A2 = np.dot(O1, self.W2.T) + self.b2\n        O2 = sigmoid(A2)\n\n        A3 = np.dot(O2, self.W3.T) + self.b3\n        O3 = sigmoid(A3)\n\n        # When Y is none, simply return the predictions. Else compute the loss\n        if Y is not None:\n            loss = -np.sum((1 - Y) * np.log(1 - O3) + Y * np.log(O3)) # TODO cross-entropy loss\n            # normalize loss by batch size\n            loss = loss.sum() / X.shape[0]\n        else:\n            loss = np.nan\n\n        if do_backward:\n            A3_grad = (O3 - Y) / X.shape[0]\n            self.b3_grad = A3_grad.sum(0)\n            self.W3_grad = np.dot(A3_grad.T, O2)\n\n            O2_grad = np.dot(A3_grad, self.W3)\n            A2_grad = O2_grad * O2 * (1 - O2)\n            self.b2_grad = A2_grad.sum(0)\n            self.W2_grad = np.dot(A2_grad.T, O1)\n\n            O1_grad = np.dot(A2_grad, self.W2)\n            A1_grad = O1_grad * O1 * (1 - O1)\n            self.b1_grad = A1_grad.sum(0)\n            self.W1_grad = np.dot(A1_grad.T, X)\n\n        return O3, loss",
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 168
    },
    "id": "rnz6CndQ-NRI",
    "cell_id": "00039-492167fa-f9d1-4107-b677-a30e38fbc275",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3bc915",
    "execution_start": 1647801744516,
    "execution_millis": 27837,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 747.75
   },
   "source": "net = DeepNet(3, [2, 2], dtype=np.float64)\n\nalpha = 0.1  # set a learning rate\n\nfor i in range(100000):\n    _, loss = net.forward(X3, Y3, do_backward=True)\n    if (i % 5000) == 0:\n        print(f\"after {i} steps \\tloss={loss}\")\n    for param_name in [\"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"]:\n        param = getattr(net, param_name)\n        # Hint: use the construct `param[:]` to change the contents of the array!\n        # Doing instead `param = new_val` simply changes to what the variable\n        # param points to, without affecting the network!\n        # alternatively, you could do setattr(net, param_name, new_value)\n        param[:] = param[:] - alpha * getattr(net, param_name + \"_grad\")",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "text": "after 0 steps \tloss=0.7091192988713748\nafter 5000 steps \tloss=0.6931464318654379\nafter 10000 steps \tloss=0.693146359668597\nafter 15000 steps \tloss=0.693146283429062\nafter 20000 steps \tloss=0.6931462025377678\nafter 25000 steps \tloss=0.6931461163174114\nafter 30000 steps \tloss=0.6931460240077673\nafter 35000 steps \tloss=0.6931459247482701\nafter 40000 steps \tloss=0.6931458175571119\nafter 45000 steps \tloss=0.6931457013058882\nafter 50000 steps \tloss=0.693145574688552\nafter 55000 steps \tloss=0.6931454361830545\nafter 60000 steps \tloss=0.6931452840035269\nafter 65000 steps \tloss=0.6931451160401583\nafter 70000 steps \tloss=0.6931449297829231\nafter 75000 steps \tloss=0.6931447222239377\nafter 80000 steps \tloss=0.693144489731256\nafter 85000 steps \tloss=0.6931442278840881\nafter 90000 steps \tloss=0.6931439312553279\nafter 95000 steps \tloss=0.6931435931211982\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00040-94f1cec2-717a-4f39-8e9d-a865eb227dab",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3b4e28ee",
    "execution_start": 1647801772362,
    "execution_millis": 20,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 112.1875
   },
   "source": "print(f\"accuracy: {(net.forward(X3)[0].round() == Y3).mean()}\")",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": "accuracy: 0.375\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 6",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 174
    },
    "id": "4PcNxrCt-NcN",
    "cell_id": "00041-cf662e6f-439c-4e18-93c4-a95d67290ab7",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 180
    },
    "id": "6Brepirl-Nln",
    "cell_id": "00042-4449befc-46a2-4aed-b0b2-3c5057dbc6ac",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "59e3fb00",
    "execution_start": 1647801772395,
    "execution_millis": 62,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1233
   },
   "source": "from typing import List\n\nclass Net:\n    def __init__(self, in_features, num_hidden: List[int], dtype=np.float32):\n        # First layer\n        self.W = [np.zeros((num_hidden[0], in_features), dtype=dtype)]\n        self.b = [np.zeros((num_hidden[0],), dtype=dtype)]\n\n        # Add other layers\n        for i in range(1, len(num_hidden)):\n            self.W.append(np.zeros((num_hidden[i], num_hidden[i - 1]), dtype=dtype))\n            self.b.append(np.zeros((num_hidden[i], ), dtype=dtype))\n\n        # Last layer\n        self.W.append(np.zeros((1, num_hidden[-1]), dtype=dtype))\n        self.b.append(np.zeros((1, ), dtype=dtype))\n\n        self.init_params()\n\n    def init_params(self):\n        for W, b in zip(self.W, self.b):\n            W[:] = np.random.normal(0, 0.5, W.shape)\n            b[:] = np.random.normal(0, 0.5, b.shape)\n\n    def forward(self, X, Y=None, do_backward=False):\n        # Input to neurons in 1st layer\n        A = [np.dot(X, self.W[0].T) + self.b[0]]\n        O = [sigmoid(A[0])]\n\n        for W, b in zip(self.W[1:], self.b[1:]):\n            A.append(np.dot(O[-1], W.T) + b)\n            O.append(sigmoid(A[-1]))\n\n        # When Y is none, simply return the predictions. Else compute the loss\n        if Y is not None:\n            loss = -np.sum((1 - Y) * np.log(1 - O[-1]) + Y * np.log(O[-1]))\n            # normalize loss by batch size\n            loss = loss.sum() / X.shape[0]\n        else:\n            loss = np.nan\n\n        if do_backward:\n            A_grad = [(O[-1] - Y) / X.shape[0]]\n            self.b_grad = []\n            self.W_grad = []\n\n            for idx in range(len(self.W) - 1):\n                self.b_grad.append(A_grad[idx].sum(0))\n                self.W_grad.append(np.dot(A_grad[idx].T, O[-(idx + 2)]))\n                O_grad = np.dot(A_grad[idx], self.W[-(idx + 1)])\n                A_grad.append(O_grad * O[-(idx + 2)] * (1 - O[-(idx + 2)]))\n\n            self.b_grad.append(A_grad[-1].sum(0))\n            self.W_grad.append(np.dot(A_grad[-1].T, X))\n\n            self.b_grad = self.b_grad[::-1]\n            self.W_grad = self.W_grad[::-1]\n        return O[-1], loss\n\n    def backward(self, alpha: float = 0.1):\n        for W, W_grad in zip(self.W, self.W_grad):\n            W[:] = W[:] - alpha * W_grad\n\n        for b, b_grad in zip(self.b, self.b_grad):\n            b[:] = b[:] - alpha * b_grad",
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00043-dd065236-e397-4fd9-a2f9-acdb234b94d4",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a7ba7889",
    "execution_start": 1647801772457,
    "execution_millis": 0,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 99
   },
   "source": "def ReLU(x):\n    return np.fmax(0, x)",
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00044-a708d55b-1e81-455b-b966-cf141e43cb25",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1fd51fe6",
    "execution_start": 1647801772458,
    "execution_millis": 77,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1647
   },
   "source": "from typing import List, Union\n\nclass Net:\n    def __init__(self, in_features, num_hidden: Union[List[int], int], dtype=np.float32, activation=\"sigmoid\"):\n        if isinstance(num_hidden, int):\n            num_hidden = [num_hidden]\n\n        self.activation = activation.lower()\n\n        # First layer\n        self.W = [np.zeros((num_hidden[0], in_features), dtype=dtype)]\n        self.b = [np.zeros((num_hidden[0],), dtype=dtype)]\n\n        # Add other layers\n        for i in range(1, len(num_hidden)):\n            self.W.append(np.zeros((num_hidden[i], num_hidden[i - 1]), dtype=dtype))\n            self.b.append(np.zeros((num_hidden[i], ), dtype=dtype))\n\n        # Last layer\n        self.W.append(np.zeros((1, num_hidden[-1]), dtype=dtype))\n        self.b.append(np.zeros((1, ), dtype=dtype))\n\n        self.init_params()\n\n    def init_params(self):\n        for W, b in zip(self.W, self.b):\n            W[:] = np.random.normal(0, 0.5, W.shape)\n            b[:] = np.random.normal(0, 0.5, b.shape)\n\n    def forward(self, X, Y=None, do_backward=False):\n        # Input to neurons in 1st layer\n        A = [np.dot(X, self.W[0].T) + self.b[0]]\n        if self.activation == \"sigmoid\":\n            O = [sigmoid(A[0])]\n        elif self.activation == \"relu\":\n            O = [ReLU(A[0])]\n        else:\n            raise ValueError(\"activation not known.\")\n\n        for W, b in zip(self.W[1:-1], self.b[1:-1]):\n            A.append(np.dot(O[-1], W.T) + b)\n            if self.activation == \"sigmoid\":\n                O.append(sigmoid(A[-1]))\n            elif self.activation == \"relu\":\n                O.append(ReLU(A[-1]))\n            else:\n                raise ValueError(\"activation not known.\")\n            \n        A.append(np.dot(O[-1], self.W[-1].T) + self.b[-1])\n        O.append(sigmoid(A[-1]))\n\n        # When Y is none, simply return the predictions. Else compute the loss\n        if Y is not None:\n            loss = -np.sum((1 - Y) * np.log(1 - O[-1]) + Y * np.log(O[-1]))\n            # normalize loss by batch size\n            loss = loss.sum() / X.shape[0]\n        else:\n            loss = np.nan\n\n        if do_backward:\n            A_grad = [(O[-1] - Y) / X.shape[0]]\n            self.b_grad = []\n            self.W_grad = []\n\n            for idx in range(len(self.W) - 1):\n                self.b_grad.append(A_grad[idx].sum(0))\n                self.W_grad.append(np.dot(A_grad[idx].T, O[-(idx + 2)]))\n                O_grad = np.dot(A_grad[idx], self.W[-(idx + 1)])\n                if self.activation == \"sigmoid\":\n                    A_grad.append(O_grad * O[-(idx + 2)] * (1 - O[-(idx + 2)]))\n                elif self.activation == \"relu\":\n                    A_grad.append(O_grad * np.where(O[-(idx + 2)] == 0, 0, 1))\n                else:\n                    raise ValueError(\"activation not known.\")\n\n            self.b_grad.append(A_grad[-1].sum(0))\n            self.W_grad.append(np.dot(A_grad[-1].T, X))\n\n            self.b_grad = self.b_grad[::-1]\n            self.W_grad = self.W_grad[::-1]\n        return O[-1], loss\n\n    def backward(self, alpha: float = 0.1):\n        for W, W_grad in zip(self.W, self.W_grad):\n            W[:] = W[:] - alpha * W_grad\n\n        for b, b_grad in zip(self.b, self.b_grad):\n            b[:] = b[:] - alpha * b_grad",
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00045-eb1a7b64-f64e-4f4d-a2c7-a7a5070fc0b3",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "aa0a49c8",
    "execution_start": 1647801772535,
    "execution_millis": 27439,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 585.75
   },
   "source": "net = Net(3, 2 * [10], np.float64)\nfor i in range(100000):\n    y_hat, loss = net.forward(X3, Y3, do_backward=True)\n    net.backward(0.1)\n    if (i % 5000) == 0:\n        print(f\"after {i:6d} steps \\tloss={loss:.6e} \\taccuracy={(y_hat.round() == Y3).mean()}\")",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": "after      0 steps \tloss=7.045071e-01 \taccuracy=0.5\nafter   5000 steps \tloss=6.878353e-01 \taccuracy=0.75\nafter  10000 steps \tloss=1.229543e-02 \taccuracy=1.0\nafter  15000 steps \tloss=2.592589e-03 \taccuracy=1.0\nafter  20000 steps \tloss=1.341622e-03 \taccuracy=1.0\nafter  25000 steps \tloss=8.827031e-04 \taccuracy=1.0\nafter  30000 steps \tloss=6.497813e-04 \taccuracy=1.0\nafter  35000 steps \tloss=5.104793e-04 \taccuracy=1.0\nafter  40000 steps \tloss=4.184218e-04 \taccuracy=1.0\nafter  45000 steps \tloss=3.533507e-04 \taccuracy=1.0\nafter  50000 steps \tloss=3.050698e-04 \taccuracy=1.0\nafter  55000 steps \tloss=2.679108e-04 \taccuracy=1.0\nafter  60000 steps \tloss=2.384811e-04 \taccuracy=1.0\nafter  65000 steps \tloss=2.146306e-04 \taccuracy=1.0\nafter  70000 steps \tloss=1.949332e-04 \taccuracy=1.0\nafter  75000 steps \tloss=1.784068e-04 \taccuracy=1.0\nafter  80000 steps \tloss=1.643542e-04 \taccuracy=1.0\nafter  85000 steps \tloss=1.522669e-04 \taccuracy=1.0\nafter  90000 steps \tloss=1.417657e-04 \taccuracy=1.0\nafter  95000 steps \tloss=1.325624e-04 \taccuracy=1.0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00046-991958e2-dd48-4c0c-8ab2-6261889f8f66",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "72f4e69d",
    "execution_start": 1647801799994,
    "execution_millis": 22712,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 585.75
   },
   "source": "net = Net(3, 2 * [10], np.float64, \"relu\")\nfor i in range(100000):\n    y_hat, loss = net.forward(X3, Y3, do_backward=True)\n    net.backward(0.1)\n    if (i % 5000) == 0:\n        print(f\"after {i:6d} steps \\tloss={loss:.6e} \\taccuracy={(y_hat.round() == Y3).mean()}\")",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "text": "after      0 steps \tloss=7.151827e-01 \taccuracy=0.5\nafter   5000 steps \tloss=3.952706e-04 \taccuracy=1.0\nafter  10000 steps \tloss=1.633950e-04 \taccuracy=1.0\nafter  15000 steps \tloss=9.899737e-05 \taccuracy=1.0\nafter  20000 steps \tloss=6.975651e-05 \taccuracy=1.0\nafter  25000 steps \tloss=5.330552e-05 \taccuracy=1.0\nafter  30000 steps \tloss=4.285470e-05 \taccuracy=1.0\nafter  35000 steps \tloss=3.567154e-05 \taccuracy=1.0\nafter  40000 steps \tloss=3.045333e-05 \taccuracy=1.0\nafter  45000 steps \tloss=2.650022e-05 \taccuracy=1.0\nafter  50000 steps \tloss=2.340973e-05 \taccuracy=1.0\nafter  55000 steps \tloss=2.093204e-05 \taccuracy=1.0\nafter  60000 steps \tloss=1.890391e-05 \taccuracy=1.0\nafter  65000 steps \tloss=1.721572e-05 \taccuracy=1.0\nafter  70000 steps \tloss=1.578975e-05 \taccuracy=1.0\nafter  75000 steps \tloss=1.457015e-05 \taccuracy=1.0\nafter  80000 steps \tloss=1.351648e-05 \taccuracy=1.0\nafter  85000 steps \tloss=1.259722e-05 \taccuracy=1.0\nafter  90000 steps \tloss=1.178896e-05 \taccuracy=1.0\nafter  95000 steps \tloss=1.107292e-05 \taccuracy=1.0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00047-d0d1a914-af9d-449f-b773-da73226cbe91",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "72a87bf8",
    "execution_start": 1647801822717,
    "execution_millis": 45748,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 585.75
   },
   "source": "net = Net(3, 5 * [8], np.float64, \"relu\")\nfor i in range(100000):\n    y_hat, loss = net.forward(X3, Y3, do_backward=True)\n    net.backward(0.1)\n    if (i % 5000) == 0:\n        print(f\"after {i:6d} steps \\tloss={loss:.6e} \\taccuracy={(y_hat.round() == Y3).mean()}\")",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "text": "after      0 steps \tloss=7.045973e-01 \taccuracy=0.375\nafter   5000 steps \tloss=8.304026e-05 \taccuracy=1.0\nafter  10000 steps \tloss=3.400505e-05 \taccuracy=1.0\nafter  15000 steps \tloss=2.047660e-05 \taccuracy=1.0\nafter  20000 steps \tloss=1.435681e-05 \taccuracy=1.0\nafter  25000 steps \tloss=1.093084e-05 \taccuracy=1.0\nafter  30000 steps \tloss=8.762864e-06 \taccuracy=1.0\nafter  35000 steps \tloss=7.279615e-06 \taccuracy=1.0\nafter  40000 steps \tloss=6.202652e-06 \taccuracy=1.0\nafter  45000 steps \tloss=5.388071e-06 \taccuracy=1.0\nafter  50000 steps \tloss=4.752085e-06 \taccuracy=1.0\nafter  55000 steps \tloss=4.242928e-06 \taccuracy=1.0\nafter  60000 steps \tloss=3.826412e-06 \taccuracy=1.0\nafter  65000 steps \tloss=3.480229e-06 \taccuracy=1.0\nafter  70000 steps \tloss=3.188135e-06 \taccuracy=1.0\nafter  75000 steps \tloss=2.938563e-06 \taccuracy=1.0\nafter  80000 steps \tloss=2.723112e-06 \taccuracy=1.0\nafter  85000 steps \tloss=2.535431e-06 \taccuracy=1.0\nafter  90000 steps \tloss=2.370441e-06 \taccuracy=1.0\nafter  95000 steps \tloss=2.224460e-06 \taccuracy=1.0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00048-3ade0de5-5673-452a-9eef-a4339db79cea",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a0bd49d7",
    "execution_start": 1647801868466,
    "execution_millis": 58522,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 585.75
   },
   "source": "net = Net(3, 7 * [8], np.float64, \"relu\")\nfor i in range(100000):\n    y_hat, loss = net.forward(X3, Y3, do_backward=True)\n    net.backward(0.1)\n    if (i % 5000) == 0:\n        print(f\"after {i:6d} steps \\tloss={loss:.6e} \\taccuracy={(y_hat.round() == Y3).mean()}\")",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "text": "after      0 steps \tloss=1.182528e+00 \taccuracy=0.5\nafter   5000 steps \tloss=2.800468e-05 \taccuracy=1.0\nafter  10000 steps \tloss=1.124179e-05 \taccuracy=1.0\nafter  15000 steps \tloss=6.661116e-06 \taccuracy=1.0\nafter  20000 steps \tloss=4.628350e-06 \taccuracy=1.0\nafter  25000 steps \tloss=3.503195e-06 \taccuracy=1.0\nafter  30000 steps \tloss=2.798009e-06 \taccuracy=1.0\nafter  35000 steps \tloss=2.324725e-06 \taccuracy=1.0\nafter  40000 steps \tloss=1.980627e-06 \taccuracy=1.0\nafter  45000 steps \tloss=1.720043e-06 \taccuracy=1.0\nafter  50000 steps \tloss=1.516786e-06 \taccuracy=1.0\nafter  55000 steps \tloss=1.353844e-06 \taccuracy=1.0\nafter  60000 steps \tloss=1.220566e-06 \taccuracy=1.0\nafter  65000 steps \tloss=1.109640e-06 \taccuracy=1.0\nafter  70000 steps \tloss=1.016037e-06 \taccuracy=1.0\nafter  75000 steps \tloss=9.360711e-07 \taccuracy=1.0\nafter  80000 steps \tloss=8.670257e-07 \taccuracy=1.0\nafter  85000 steps \tloss=8.068522e-07 \taccuracy=1.0\nafter  90000 steps \tloss=7.539886e-07 \taccuracy=1.0\nafter  95000 steps \tloss=7.072047e-07 \taccuracy=1.0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00049-edfc57ed-db72-4e60-b58b-d2fc02b0c28e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b0e8af23",
    "execution_start": 1647801927001,
    "execution_millis": 68558,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 585.75
   },
   "source": "net = Net(3, 10 * [8], np.float64, \"relu\")\nfor i in range(100000):\n    y_hat, loss = net.forward(X3, Y3, do_backward=True)\n    net.backward(0.1)\n    if (i % 5000) == 0:\n        print(f\"after {i:6d} steps \\tloss={loss:.6e} \\taccuracy={(y_hat.round() == Y3).mean()}\")",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "text": "after      0 steps \tloss=7.324172e-01 \taccuracy=0.5\nafter   5000 steps \tloss=3.128005e-01 \taccuracy=0.875\nafter  10000 steps \tloss=3.127714e-01 \taccuracy=0.875\nafter  15000 steps \tloss=3.127629e-01 \taccuracy=0.875\nafter  20000 steps \tloss=3.127604e-01 \taccuracy=0.875\nafter  25000 steps \tloss=3.127583e-01 \taccuracy=0.875\nafter  30000 steps \tloss=3.127563e-01 \taccuracy=0.875\nafter  35000 steps \tloss=3.127553e-01 \taccuracy=0.875\nafter  40000 steps \tloss=3.127554e-01 \taccuracy=0.875\nafter  45000 steps \tloss=3.127543e-01 \taccuracy=0.875\nafter  50000 steps \tloss=3.127540e-01 \taccuracy=0.875\nafter  55000 steps \tloss=3.127536e-01 \taccuracy=0.875\nafter  60000 steps \tloss=3.127548e-01 \taccuracy=0.875\nafter  65000 steps \tloss=3.127533e-01 \taccuracy=0.875\nafter  70000 steps \tloss=3.127690e-01 \taccuracy=0.875\nafter  75000 steps \tloss=3.127557e-01 \taccuracy=0.875\nafter  80000 steps \tloss=3.127529e-01 \taccuracy=0.875\nafter  85000 steps \tloss=3.127528e-01 \taccuracy=0.875\nafter  90000 steps \tloss=3.127527e-01 \taccuracy=0.875\nafter  95000 steps \tloss=3.127526e-01 \taccuracy=0.875\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00050-a59a1e2c-bd96-48c9-a2e1-05e926fa450e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "20618355",
    "execution_start": 1647801995596,
    "execution_millis": 26381,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 484.8125
   },
   "source": "net = Net(3, 12 * [8], np.float64, \"relu\")\nfor i in range(30000):\n    y_hat, loss = net.forward(X3, Y3, do_backward=True)\n    net.backward(0.1)\n    if (i % 2000) == 0:\n        print(f\"after {i:6d} steps \\tloss={loss:.6e} \\taccuracy={(y_hat.round() == Y3).mean()}\")",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "text": "after      0 steps \tloss=6.933769e-01 \taccuracy=0.5\nafter   2000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter   4000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter   6000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter   8000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  10000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  12000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  14000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  16000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  18000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  20000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  22000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  24000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  26000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  28000 steps \tloss=6.931472e-01 \taccuracy=0.5\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00051-8463c655-e0b9-47ff-9181-f9b25459f5dc",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a0bd49d7",
    "execution_start": 1647802022000,
    "execution_millis": 48664,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 585.75
   },
   "source": "net = Net(3, 7 * [8], np.float64, \"relu\")\nfor i in range(100000):\n    y_hat, loss = net.forward(X3, Y3, do_backward=True)\n    net.backward(0.1)\n    if (i % 5000) == 0:\n        print(f\"after {i:6d} steps \\tloss={loss:.6e} \\taccuracy={(y_hat.round() == Y3).mean()}\")",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "text": "after      0 steps \tloss=7.347329e-01 \taccuracy=0.5\nafter   5000 steps \tloss=1.712248e-05 \taccuracy=1.0\nafter  10000 steps \tloss=7.287916e-06 \taccuracy=1.0\nafter  15000 steps \tloss=4.475988e-06 \taccuracy=1.0\nafter  20000 steps \tloss=3.174524e-06 \taccuracy=1.0\nafter  25000 steps \tloss=2.423006e-06 \taccuracy=1.0\nafter  30000 steps \tloss=1.947514e-06 \taccuracy=1.0\nafter  35000 steps \tloss=1.621301e-06 \taccuracy=1.0\nafter  40000 steps \tloss=1.384516e-06 \taccuracy=1.0\nafter  45000 steps \tloss=1.205270e-06 \taccuracy=1.0\nafter  50000 steps \tloss=1.065160e-06 \taccuracy=1.0\nafter  55000 steps \tloss=9.528253e-07 \taccuracy=1.0\nafter  60000 steps \tloss=8.608846e-07 \taccuracy=1.0\nafter  65000 steps \tloss=7.843243e-07 \taccuracy=1.0\nafter  70000 steps \tloss=7.196457e-07 \taccuracy=1.0\nafter  75000 steps \tloss=6.643272e-07 \taccuracy=1.0\nafter  80000 steps \tloss=6.165161e-07 \taccuracy=1.0\nafter  85000 steps \tloss=5.748281e-07 \taccuracy=1.0\nafter  90000 steps \tloss=5.381525e-07 \taccuracy=1.0\nafter  95000 steps \tloss=5.056494e-07 \taccuracy=1.0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00052-8e1f59a7-2e10-4b7d-9899-28d8efca7377",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "379e188e",
    "execution_start": 1647802070672,
    "execution_millis": 23228,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 484.8125
   },
   "source": "net = Net(3, 12 * [8], np.float64, \"sigmoid\")\nfor i in range(30000):\n    y_hat, loss = net.forward(X3, Y3, do_backward=True)\n    net.backward(0.1)\n    if (i % 2000) == 0:\n        print(f\"after {i:6d} steps \\tloss={loss:.6e} \\taccuracy={(y_hat.round() == Y3).mean()}\")",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "text": "after      0 steps \tloss=7.158116e-01 \taccuracy=0.5\nafter   2000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter   4000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter   6000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter   8000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  10000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  12000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  14000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  16000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  18000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  20000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  22000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  24000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  26000 steps \tloss=6.931472e-01 \taccuracy=0.5\nafter  28000 steps \tloss=6.931472e-01 \taccuracy=0.5\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Problem 7",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 186
    },
    "id": "nWuv7Q77-Nut",
    "cell_id": "00053-6a4cbed5-38f7-4dc2-a730-e8854f3ab14c",
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 70
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 192
    },
    "id": "avuvSoWY-N4Z",
    "cell_id": "00054-200ca3c2-5683-42dc-ab13-4b1cd593dd7a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7f59b837",
    "execution_start": 1647802093908,
    "execution_millis": 34,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1701
   },
   "source": "from typing import List, Union\n\nclass FeedbackAllignmentNet:\n    def __init__(self, in_features, num_hidden: Union[List[int], int], dtype=np.float32, activation=\"sigmoid\"):\n        if isinstance(num_hidden, int):\n            num_hidden = [num_hidden]\n\n        self.activation = activation.lower()\n\n        # First layer\n        self.W = [np.zeros((num_hidden[0], in_features), dtype=dtype)]\n        self.b = [np.zeros((num_hidden[0],), dtype=dtype)]\n\n        # Add other layers\n        for i in range(1, len(num_hidden)):\n            self.W.append(np.zeros((num_hidden[i], num_hidden[i - 1]), dtype=dtype))\n            self.b.append(np.zeros((num_hidden[i], ), dtype=dtype))\n\n        # Last layer\n        self.W.append(np.zeros((1, num_hidden[-1]), dtype=dtype))\n        self.b.append(np.zeros((1, ), dtype=dtype))\n\n        self.init_params()\n\n    def init_params(self):\n        self.backward_weights = []\n\n        for W, b in zip(self.W, self.b):\n            W[:] = np.random.normal(0, 0.5, W.shape)\n            b[:] = np.random.normal(0, 0.5, b.shape)\n            self.backward_weights.append(np.random.normal(0, 0.5, W.T.shape))\n\n    def forward(self, X, Y=None, do_backward=False):\n        # Input to neurons in 1st layer\n        A = [np.dot(X, self.W[0].T) + self.b[0]]\n        if self.activation == \"sigmoid\":\n            O = [sigmoid(A[0])]\n        elif self.activation == \"relu\":\n            O = [ReLU(A[0])]\n        else:\n            raise ValueError(\"activation not known.\")\n\n        for W, b in zip(self.W[1:-1], self.b[1:-1]):\n            A.append(np.dot(O[-1], W.T) + b)\n            if self.activation == \"sigmoid\":\n                O.append(sigmoid(A[-1]))\n            elif self.activation == \"relu\":\n                O.append(ReLU(A[-1]))\n            else:\n                raise ValueError(\"activation not known.\")\n            \n        A.append(np.dot(O[-1], self.W[-1].T) + self.b[-1])\n        O.append(sigmoid(A[-1]))\n\n        # When Y is none, simply return the predictions. Else compute the loss\n        if Y is not None:\n            loss = -np.sum((1 - Y) * np.log(1 - O[-1]) + Y * np.log(O[-1]))\n            # normalize loss by batch size\n            loss = loss.sum() / X.shape[0]\n        else:\n            loss = np.nan\n\n        if do_backward:\n            A_grad = [(O[-1] - Y) / X.shape[0]]\n            self.b_grad = []\n            self.W_grad = []\n\n            for idx in range(len(self.W) - 1):\n                self.b_grad.append(A_grad[idx].sum(0))\n                self.W_grad.append(np.dot(A_grad[idx].T, O[-(idx + 2)]))\n                O_grad = np.dot(A_grad[idx], self.backward_weights[-(idx + 1)].T)\n                if self.activation == \"sigmoid\":\n                    A_grad.append(O_grad * O[-(idx + 2)] * (1 - O[-(idx + 2)]))\n                elif self.activation == \"relu\":\n                    A_grad.append(O_grad * np.where(O[-(idx + 2)] == 0, 0, 1))\n                else:\n                    raise ValueError(\"activation not known.\")\n\n            self.b_grad.append(A_grad[-1].sum(0))\n            self.W_grad.append(np.dot(A_grad[-1].T, X))\n\n            self.b_grad = self.b_grad[::-1]\n            self.W_grad = self.W_grad[::-1]\n        return O[-1], loss\n\n    def backward(self, alpha: float = 0.1):\n        for W, W_grad in zip(self.W, self.W_grad):\n            W[:] = W[:] - alpha * W_grad\n\n        for b, b_grad in zip(self.b, self.b_grad):\n            b[:] = b[:] - alpha * b_grad",
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00055-c6b7a5a9-bfdc-4030-804a-3513e03d382e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "96a3fb9e",
    "execution_start": 1647802093954,
    "execution_millis": 12007,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 484.8125
   },
   "source": "net = FeedbackAllignmentNet(3, 5 * [8], np.float64, \"sigmoid\")\nfor i in range(30000):\n    y_hat, loss = net.forward(X3, Y3, do_backward=True)\n    net.backward(0.1)\n    if (i % 2000) == 0:\n        print(f\"after {i:6d} steps \\tloss={loss:.6e} \\taccuracy={(y_hat.round() == Y3).mean()}\")",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "text": "after      0 steps \tloss=8.845535e-01 \taccuracy=0.5\nafter   2000 steps \tloss=6.931477e-01 \taccuracy=0.5\nafter   4000 steps \tloss=6.931477e-01 \taccuracy=0.5\nafter   6000 steps \tloss=6.931477e-01 \taccuracy=0.5\nafter   8000 steps \tloss=6.931477e-01 \taccuracy=0.5\nafter  10000 steps \tloss=6.931477e-01 \taccuracy=0.5\nafter  12000 steps \tloss=6.931477e-01 \taccuracy=0.5\nafter  14000 steps \tloss=6.931477e-01 \taccuracy=0.5\nafter  16000 steps \tloss=6.931477e-01 \taccuracy=0.5\nafter  18000 steps \tloss=6.931477e-01 \taccuracy=0.5\nafter  20000 steps \tloss=6.931477e-01 \taccuracy=0.5\nafter  22000 steps \tloss=6.931477e-01 \taccuracy=0.5\nafter  24000 steps \tloss=6.931477e-01 \taccuracy=0.5\nafter  26000 steps \tloss=6.931477e-01 \taccuracy=0.5\nafter  28000 steps \tloss=6.931477e-01 \taccuracy=0.5\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00056-e17988ba-daa1-4b25-836f-c9d3ee08b0f1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e471f0e3",
    "execution_start": 1647802105971,
    "execution_millis": 7130,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 485
   },
   "source": "net = FeedbackAllignmentNet(3, 2 * [8], np.float64, \"sigmoid\")\nfor i in range(30000):\n    y_hat, loss = net.forward(X3, Y3, do_backward=True)\n    net.backward(0.1)\n    if (i % 2000) == 0:\n        print(f\"after {i:6d} steps \\tloss={loss:.6e} \\taccuracy={(y_hat.round() == Y3).mean()}\")",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "text": "after      0 steps \tloss=6.937305e-01 \taccuracy=0.625\nafter   2000 steps \tloss=6.931187e-01 \taccuracy=0.375\nafter   4000 steps \tloss=6.927120e-01 \taccuracy=0.375\nafter   6000 steps \tloss=6.915275e-01 \taccuracy=0.5\nafter   8000 steps \tloss=6.875188e-01 \taccuracy=0.75\nafter  10000 steps \tloss=6.751284e-01 \taccuracy=0.75\nafter  12000 steps \tloss=6.356888e-01 \taccuracy=0.75\nafter  14000 steps \tloss=4.920509e-01 \taccuracy=1.0\nafter  16000 steps \tloss=2.614069e-01 \taccuracy=1.0\nafter  18000 steps \tloss=1.278636e-01 \taccuracy=1.0\nafter  20000 steps \tloss=7.270326e-02 \taccuracy=1.0\nafter  22000 steps \tloss=4.745700e-02 \taccuracy=1.0\nafter  24000 steps \tloss=3.402614e-02 \taccuracy=1.0\nafter  26000 steps \tloss=2.599605e-02 \taccuracy=1.0\nafter  28000 steps \tloss=2.076820e-02 \taccuracy=1.0\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00057-29aeb7a7-c359-4f20-92d1-0ff3bb6d1835",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b623e53d",
    "execution_start": 1647802112701,
    "execution_millis": 4,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "source": "",
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=7dfe7d92-83a2-44ca-8f65-82cd0b077078' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Assignment1.ipynb",
   "provenance": []
  },
  "deepnote": {},
  "deepnote_app_layout": "article",
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "afa86780-116b-444f-aed1-5597c87c0bb2",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 }
}